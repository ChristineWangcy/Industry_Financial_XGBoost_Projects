{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "currency exchange rate prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "# Predict next 5 days change for a pair of currency rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBNaLR1UOrol"
      },
      "source": [
        "pair_currency = 'EUNO'\n",
        "currency1 = pair_currency[:2]\n",
        "currency2 = pair_currency[2:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8453JSl4uYIb"
      },
      "source": [
        "# install and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sX_xtn57WTo"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "!pip install category_encoders==2.*\n",
        "!pip install pdpbox\n",
        "!pip install shap\n",
        "!pip install --upgrade numpy==1.19.1\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='xgboost')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Kwz804WIdl"
      },
      "source": [
        "# data analysis and wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "\n",
        "# encoders\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, r2_score, \\\n",
        " classification_report, roc_auc_score, plot_confusion_matrix, classification_report\n",
        "\n",
        "# pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Boosted Models\n",
        "# Use this one if you have an M1 chip.\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost.sklearn import XGBRegressor\n",
        "\n",
        "# Permutation Importance\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# for displaying images and html\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "\n",
        "# Partial Dependence Plot\n",
        "from pdpbox.pdp import pdp_isolate, pdp_plot, pdp_interact, pdp_interact_plot\n",
        "\n",
        "# shap\n",
        "import shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6KJ7OuYx9kj"
      },
      "source": [
        "# Wrangling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VavcAuBPQKKd"
      },
      "source": [
        "pd.read_csv(\"newEUNZ.csv\", parse_dates=['DATE'], index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah_3gggdeyg7"
      },
      "source": [
        "def wrangle(file):\n",
        "  df = pd.read_csv(file, parse_dates=['DATE'], index_col=0)\n",
        "  df.dropna(inplace=True)\n",
        "  df = df.sort_index(ascending=True)\n",
        "  df = df.applymap(lambda x: float(x))\n",
        "  if file[5:7] == currency1:\n",
        "    df['close'] = 1/df['close']\n",
        "  print('------file started: ', file)\n",
        "\n",
        "  # add more features - X\n",
        "  df['today_change'] = df['close'] / df['close'].shift(1) - 1\n",
        "  \n",
        "  df['5days_change'] = df['close']/df['close'].shift(5) - 1\n",
        "  df['10days_change'] = df['close']/df['close'].shift(10) - 1\n",
        "  df['30days_change'] = df['close']/df['close'].shift(30) - 1\n",
        "  df['60days_change'] = df['close']/df['close'].shift(60) - 1\n",
        "  \n",
        "  df['bias_10days_ave'] = df['close']/df['close'].rolling(window=10).mean() - 1\n",
        "  df['bias_30days_ave'] = df['close']/df['close'].rolling(window=30).mean() - 1\n",
        "  df['bias_60days_ave'] = df['close']/df['close'].rolling(window=60).mean() - 1\n",
        "  df['bias_120days_ave'] = df['close']/df['close'].rolling(window=120).mean() - 1\n",
        "  df['bias_120days_ave'] = df['bias_120days_ave'].fillna(df['bias_60days_ave'])\n",
        "\n",
        "  # target - y\n",
        "  df['next5days_change'] = df['close'].shift(-5)/df['close'] - 1\n",
        " \n",
        "  df.drop(columns=['close'], inplace=True)\n",
        "  \n",
        "  if file[5:7] == currency1:\n",
        "    df.columns = file[5:7] + file[3:5] + '_' + df.columns\n",
        "  else:\n",
        "    df.columns = file[3:7] + '_' + df.columns\n",
        "  print('features added finished: ------', file)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSNLu9JJWf3z"
      },
      "source": [
        "data = pd.DataFrame(columns=['DATE'])\n",
        "data = data.set_index('DATE')\n",
        "dir = os.getcwd()\n",
        "for f in os.listdir(dir):\n",
        "  if f.find(currency1) != -1:\n",
        "    df = wrangle(f)\n",
        "    data = pd.concat([df, data], axis=1,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb9AR9cMdzlL"
      },
      "source": [
        "for f in os.listdir(dir):\n",
        "  if (f[-6:-4] == currency2) & (f[3:7] != pair_currency):\n",
        "    print(f)\n",
        "    df = wrangle(f)\n",
        "    data = pd.concat([df, data], axis=1)\n",
        "    print(data.shape)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09G4purPeR9q"
      },
      "source": [
        "# add more feature to all data\n",
        "today_change_columns = [c for c in data.columns if c.find('today_change') != -1]\n",
        "days5_change_columns = [c for c in data.columns if c.find('5days_change') != -1]\n",
        "days10_change_columns = [c for c in data.columns if c.find('10days_change') != -1]\n",
        "\n",
        "data['max_today_change'] = data[today_change_columns].max(axis=1)\n",
        "data['max_5days_change'] = data[days5_change_columns].max(axis=1)\n",
        "data['max_10days_change'] = data[days10_change_columns].max(axis=1)\n",
        "data['min_today_change'] = data[today_change_columns].min(axis=1)\n",
        "data['min_5days_change'] = data[days5_change_columns].min(axis=1)\n",
        "data['min_10days_change'] = data[days10_change_columns].min(axis=1)\n",
        "\n",
        "bias_10days_columns = [c for c in data.columns if c.find('bias_10days') != -1]\n",
        "bias_30days_columns = [c for c in data.columns if c.find('bias_30days') != -1]\n",
        "bias_60days_columns = [c for c in data.columns if c.find('bias_60days') != -1]\n",
        "bias_120days_columns = [c for c in data.columns if c.find('bias_120days') != -1]\n",
        "\n",
        "data['max_bias_10days'] = data[bias_10days_columns].max(axis=1)\n",
        "data['max_bias_30days'] = data[bias_30days_columns].max(axis=1)\n",
        "data['max_bias_60days'] = data[bias_60days_columns].max(axis=1)\n",
        "\n",
        "data['min_bias_10days'] = data[bias_10days_columns].min(axis=1)\n",
        "data['min_bias_30days'] = data[bias_30days_columns].min(axis=1)\n",
        "data['min_bias_60days'] = data[bias_60days_columns].min(axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gs13TOPiPFt"
      },
      "source": [
        "data.dropna(axis=0, thresh= 60, inplace=True)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2MIfvTP2HIT"
      },
      "source": [
        "print(data.columns)\n",
        "data.tail(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5joJuaFJ0eP"
      },
      "source": [
        "## Prepare training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx3JQf3tk7d_"
      },
      "source": [
        "data1 = data[data[pair_currency + '_next5days_change'].notna()].copy()\n",
        "target = pair_currency + '_next5days_change'\n",
        "X = data1.drop(columns=[c for c in data1.columns if c.find('next5days') != -1])\n",
        "y = data1[target]\n",
        "X.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOC2U__LlPR4"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnNc4v1j-Rv"
      },
      "source": [
        "###target training data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSMMQF6MRLrJ"
      },
      "source": [
        "y_train.plot(kind='hist')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcZ9P4og9d6V"
      },
      "source": [
        "# Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBg_AS2T7SLJ"
      },
      "source": [
        "## Baseline error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ESh0G197UOf"
      },
      "source": [
        "baseline = mean_absolute_error(y_train, [y_train.mean()] * len(y_train))\n",
        "print('Baseline error: ', baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b__qGh-Q966F"
      },
      "source": [
        "model_lr = make_pipeline(\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    Ridge(random_state=42)\n",
        ")\n",
        "model_lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKv_WkLukni3"
      },
      "source": [
        "## Ridge absolute error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYDwXXdq97LM"
      },
      "source": [
        "print(\"train error: \", mean_absolute_error(y_train, model_lr.predict(X_train)))\n",
        "print(\"validation error: \", mean_absolute_error(y_val, model_lr.predict(X_val)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP-ENBxYTKom"
      },
      "source": [
        "## Tuning Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFaZtKAtwZHG"
      },
      "source": [
        "train_mean_absolute_errors = []\n",
        "val_mean_absolute_errors = []\n",
        "alphas = np.arange(0,2,0.1)\n",
        "print(alphas)\n",
        "for a in alphas:\n",
        "  model_lr = make_pipeline(\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    Ridge(random_state=42, alpha=a)\n",
        ")\n",
        "  model_lr.fit(X_train, y_train)\n",
        "  train_mean_absolute_errors.append(mean_absolute_error(y_train, model_lr.predict(X_train)))\n",
        "  val_mean_absolute_errors.append(mean_absolute_error(y_val, model_lr.predict(X_val)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2l-P2yhwZgH"
      },
      "source": [
        "### Ridge absolute error graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpgCVAaawZgF"
      },
      "source": [
        "#plt.plot(alphas, train_mean_absolute_errors, color='red')\n",
        "plt.plot(alphas, val_mean_absolute_errors, color='blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b34bhF7wkzfq"
      },
      "source": [
        "###Tuned Ridge absolute error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZikmIjvXO6NO"
      },
      "source": [
        "best_alpha = alphas[val_mean_absolute_errors.index(min(val_mean_absolute_errors))]\n",
        "print('best alpha: ', best_alpha)\n",
        "model_lr = make_pipeline(\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    Ridge(random_state=42, alpha = best_alpha)\n",
        ")\n",
        "model_lr.fit(X_train, y_train)\n",
        "train_error = mean_absolute_error(y_train, model_lr.predict(X_train))\n",
        "validation_error = mean_absolute_error(y_val, model_lr.predict(X_val))\n",
        "print(\"train error: \", train_error)\n",
        "print(\"validation error: \", validation_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD-sak7rRw34"
      },
      "source": [
        "# Classified models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBvwKuIIX8xs"
      },
      "source": [
        "## prepare classified target: -1, 0 or 1 (sell, non, buy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iyn3djzYDVK"
      },
      "source": [
        "## Baseline score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v08Fp1vRWfMU"
      },
      "source": [
        "y_logistic = data1[target].apply(lambda x: -1 if x <= -0.005 else(0 if x < 0.005 else 1))\n",
        "X_train, X_val, y_train_c, y_val_c = train_test_split(X, y_logistic, test_size=0.2)\n",
        "X_train.dtypes, y_train_c.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynzaFWvJXvyk"
      },
      "source": [
        "print(y_train_c.value_counts())\n",
        "baseline = y_train_c.value_counts(normalize=True).max()\n",
        "print('Baseline accuracy score: ', baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHETGiTWVGDR"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M1DoWBGVGDR"
      },
      "source": [
        "model_lg = make_pipeline(\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(random_state=42, n_jobs=-1)\n",
        ")\n",
        "model_lg.fit(X_train, y_train_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYRvmRQzlICC"
      },
      "source": [
        "##Acuuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa6vSxZEVGDS"
      },
      "source": [
        "print(\"train accuracy_score: \", accuracy_score(y_train_c, model_lg.predict(X_train)))\n",
        "print(\"validation accuracy_score: \", accuracy_score(y_val_c, model_lg.predict(X_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZsSkuD_VGDS"
      },
      "source": [
        "## Tuning LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vIv-g6l2zk-"
      },
      "source": [
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "max_iters = np.arange(40,700,20)\n",
        "print(max_iters)\n",
        "for iter in max_iters:\n",
        "  model_lg = make_pipeline(\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(random_state=42, n_jobs=-1, max_iter=iter)\n",
        ")\n",
        "  model_lg.fit(X_train, y_train_c)\n",
        "  train_accuracy.append(accuracy_score(y_train_c, model_lg.predict(X_train)))\n",
        "  val_accuracy.append(accuracy_score(y_val_c, model_lg.predict(X_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuhp_gF_2zk-"
      },
      "source": [
        "### Logistic Regression validation accuracy score graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoX1mom42zk-"
      },
      "source": [
        "#plt.plot(max_iters, train_accuracy, color='red')\n",
        "plt.plot(max_iters, val_accuracy, color='blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X3n5q7K2zk_"
      },
      "source": [
        "###Tuned Logistic Regression Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VX3H3wUVGDS"
      },
      "source": [
        "best_max_iter = max_iters[val_accuracy.index(max(val_accuracy))]\n",
        "print('best max iter:' , best_max_iter)\n",
        "model_lg = make_pipeline(\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(random_state=42, n_jobs=-1, max_iter = best_max_iter)\n",
        ")\n",
        "model_lg.fit(X_train, y_train_c)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train_c, model_lg.predict(X_train))\n",
        "validation_accuracy = accuracy_score(y_val_c, model_lg.predict(X_val))\n",
        "print(\"train accuracy: \", train_accuracy)\n",
        "print(\"validation accuracy: \", validation_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoQAXeaxp9yS"
      },
      "source": [
        "# RandomForest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVUB2YcRSEgr"
      },
      "source": [
        "model_rf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        ")\n",
        "\n",
        "model_rf.fit(X_train, y_train_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eugJe0GylTHr"
      },
      "source": [
        "##Accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM7VKBphSOdg"
      },
      "source": [
        "print(accuracy_score(y_train_c, model_rf.predict(X_train)))\n",
        "print(accuracy_score(y_val_c, model_rf.predict(X_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pckTJuVlS4bT"
      },
      "source": [
        "## Tuning RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjjMiAKJArtl"
      },
      "source": [
        "clf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(n_jobs=-1)\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'randomforestclassifier__random_state': range(28,46,2),\n",
        "    'randomforestclassifier__n_estimators': range(70,86,2),\n",
        "    'randomforestclassifier__max_depth': range(20,34,2),\n",
        "    'randomforestclassifier__min_samples_split': range(2,4,1)\n",
        "}\n",
        "\n",
        "model_rfrs = RandomizedSearchCV(\n",
        "    clf,\n",
        "    param_distributions = param_grid,\n",
        "    n_jobs = -1,\n",
        "    cv = 10,\n",
        "    verbose = 1,\n",
        "    n_iter = 20\n",
        ")\n",
        "\n",
        "model_rfrs.fit(X_train, y_train_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQnLIOrwwl_w"
      },
      "source": [
        "best_score = model_rfrs.best_score_\n",
        "best_params = model_rfrs.best_params_\n",
        "\n",
        "print('Best score for `model`:', best_score)\n",
        "print('Best params for `model`:', best_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWLaxwA-lXTN"
      },
      "source": [
        "###Tuned accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTRyWQ2zArtn"
      },
      "source": [
        "train_accuracy = accuracy_score(y_train_c, model_rfrs.predict(X_train))\n",
        "validation_accuracy = accuracy_score(y_val_c, model_rfrs.predict(X_val))\n",
        "print(\"train accuracy: \", train_accuracy)\n",
        "print(\"validation accuracy: \", validation_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf0EmPzEmGx4"
      },
      "source": [
        "# XGB Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0f1DhM1mFl9"
      },
      "source": [
        "model_xgb = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "model_xgb.fit(X_train, y_train_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWHrvFgzttgX"
      },
      "source": [
        "##Accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XalgvzJYm8XN"
      },
      "source": [
        "train_accuracy = accuracy_score(y_train_c, model_xgb.predict(X_train))\n",
        "validation_accuracy = accuracy_score(y_val_c, model_xgb.predict(X_val))\n",
        "print(\"train accuracy: \", train_accuracy)\n",
        "print(\"validation accuracy: \", validation_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm6ipHNdIJKK"
      },
      "source": [
        "## Tuning XGB Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqiEq62rG2yE"
      },
      "source": [
        "clf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'xgbclassifier__n_estimators': range(70, 90, 2),\n",
        "    'xgbclassifier__learning_rate': np.arange(0,0.2,0.02),\n",
        "    'xgbclassifier__max_depth': range(4,12,1),\n",
        "    'xgbclassifier__max_features': range(30,48,2),\n",
        "    'xgbclassifier__subsample': np.linspace(0.8,1.2,10)\n",
        "}\n",
        "\n",
        "model_xgbrs = RandomizedSearchCV(\n",
        "    clf,\n",
        "    param_distributions = param_grid,\n",
        "    n_jobs = -1,\n",
        "    cv = 20,\n",
        "    verbose = 1,\n",
        "    n_iter = 30\n",
        ")\n",
        "\n",
        "model_xgbrs.fit(X_train, y_train_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTAdj0juG2yE"
      },
      "source": [
        "best_score = model_xgbrs.best_score_\n",
        "best_params = model_xgbrs.best_params_\n",
        "\n",
        "print('Best score for `model`:', best_score)\n",
        "print('Best params for `model`:', best_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anCzILulG2yE"
      },
      "source": [
        "###Tuned accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZvYypfPG2yF"
      },
      "source": [
        "train_accuracy = accuracy_score(y_train_c, model_xgbrs.predict(X_train))\n",
        "validation_accuracy = accuracy_score(y_val_c, model_xgbrs.predict(X_val))\n",
        "print(\"train accuracy: \", train_accuracy)\n",
        "print(\"validation accuracy: \", validation_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lgXzrprjH8M"
      },
      "source": [
        "## Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAHKvFEc_ks3"
      },
      "source": [
        "importances = model_rf.named_steps['randomforestclassifier'].feature_importances_\n",
        "columns = X_train.columns\n",
        "df_importances = pd.DataFrame(data=importances, index=X_train.columns, columns=[\"importance\"])\n",
        "df_importances.abs().sort_values(by=['importance']).tail(10).plot(kind=\"barh\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGOSgyL7cBc6"
      },
      "source": [
        "df_importances.abs().sort_values(by=['importance'])[-20:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ybpbyERmeK"
      },
      "source": [
        "## PDP plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUJpKAgjKW24"
      },
      "source": [
        "from pdpbox import pdp\n",
        "features = X_train.columns\n",
        "feature = 'EUNO_bias_10days_ave'\n",
        "#feature = \"max_5days_chang\"\n",
        "pdp_dist = pdp.pdp_isolate(model=model_rfrs, dataset=X_train, model_features=features, feature=feature)\n",
        "pdp.pdp_plot(pdp_dist, feature);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uflz_3yGNlYg"
      },
      "source": [
        "features = ['max_5days_change', 'min_5days_change']\n",
        "\n",
        "interaction = pdp_interact(\n",
        "    model=model_rfrs, \n",
        "    dataset=X_train, \n",
        "    model_features=X_train.columns, \n",
        "    features=features\n",
        ")\n",
        "\n",
        "pdp_interact_plot(interaction, plot_type='grid', feature_names=features);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRMp_VP1QcCa"
      },
      "source": [
        "# Confusion Matrix for RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3xs9C2yqSG"
      },
      "source": [
        "plot_confusion_matrix(\n",
        "    model_rfrs,\n",
        "    X_val,\n",
        "    y_val_c,\n",
        "    values_format = '.0f',\n",
        "    display_labels = ['fall', 'None', 'rise']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhZICN70Qgkf"
      },
      "source": [
        "## Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M-yYZ39QsEe"
      },
      "source": [
        "print('Fall precision: ', 173/(173 + 24 + 16))\n",
        "print('Rise precision: ', 167/(184 + 46 + 27))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}